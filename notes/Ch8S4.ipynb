{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "average-circus",
   "metadata": {},
   "source": [
    "# Varying the step size\n",
    "\n",
    "- We can get better results if we allow the step size to vary during the running of the program, with the program choosing the best value at each step.\n",
    "\n",
    "<img src='img/841.png' width=\"500\" height=\"400\">\n",
    "\n",
    "- In some regions the function is slowly varying, in which case we can accurately capture its shape with only a few, widely spaced  oints. But in the central region of the figure the function varies rapidly and in this region we need points that are more closely spaced.\n",
    "- If we are allowed to vary the size $h$ of our steps, then we can calculate the whole solution faster but still very accurately:_adaptive step size method_\n",
    "\n",
    "## Adaptive step size method\n",
    "\n",
    "- Idea: vary the step sizes $h$ so that the error introduced per unit interval in $t$ is roughly constant.\n",
    "- The method has two parts: first we have to estimate the error on our steps, then we compare that error to our required accuracy and either increase or decrease the step size to achieve the accuracy we want.\n",
    "\n",
    "### Fourth-order Runge-Kutta method\n",
    "\n",
    "- Do two steps of the solution, each of size $h$, one after another: if we start at time $t$, we will after two steps get to time $t + 2h$ and get an estimate of $x(t + 2h)$.\n",
    "- Go back to the start again, to time $t$, and we do one more Runge-Kutta step, but this time of twice the size, i.e., of size $2h$. This step also takes us to time $t + 2h$ and gives us another estimate of $x(t + 2h)$, which will usually be close to but slightly different from the first estimate.\n",
    "\n",
    "The Runge-Kutta method is accurate to fourth order but the error on the method is fifth order. That is, the size of the error on a single step is $ch^5$ to leading order for some constant $c$. If we start at time $t$ and do two steps of size $h$ then the error will be roughly $2ch^5$. That is, the true value of $x(t + 2h)$ is related to our estimated value, call it $x_1$, by \n",
    "\n",
    "$$ x(t + 2h) = x_1 + 2ch^5 $$\n",
    "\n",
    "When we do a single large step of size $2h$ we have\n",
    "\n",
    "$$ x(t + 2h) = x_2 + 32ch^5 $$\n",
    "\n",
    "Equating these two expressions we get \n",
    "\n",
    "$$ x_1 = x_2 + 30ch^5 $$\n",
    "\n",
    "which implies that the per-step error $\\epsilon =ch^5 $ on steps of size $h$ is\n",
    "\n",
    "$$ \\epsilon = ch^5 =  \\frac{1}{30}(x_1 - x_2) $$\n",
    "\n",
    "Goal: make the size of this error exactly equal to some target accuracy: what size would our steps have to be to make the size of the error exactly equal to the target? \n",
    "\n",
    "- Denote the perfect step size $h'$. If we were to take steps of size $h'$ then the error on a single step would be \n",
    "\n",
    "$$ \\epsilon' = ch'^5 = \\frac{1}{30} (x_1 - x_2)\\left( \\frac{h'}{h} \\right) ^5 $$\n",
    "\n",
    "- At the same time suppose that the target accuracy per unit time for our calculation is $\\delta $, which means that the target accuracy for a single step of size $h'$ would be $h'\\delta $. We want to find the value of $h'$ such that the actual accuracy is equal to this target accuracy: $\\epsilon' = h' \\delta $. We want the $h'$ that satisfies \n",
    "\n",
    "$$ h' = h \\left( \\frac{30 h \\delta }{|x_1 - x_2|} \\right)^{1/4} \\equiv h \\rho ^{1/4}$$\n",
    "\n",
    "- If $\\rho > 1$ then we know that the actual accuracy is better than the target accuracy, so our calculation is fine but it is wasteful. So we keep the results and move on to time $t + 2h$ to continue our solution, but we make our steps bigger the next time around to avoid this waste. If $\\rho < 1$ then the actual accuracy of our calculation is poorer than the target accuracy. We need to repeat the current step again, but with a smaller step size.\n",
    "\n",
    "This method involves more work, but the extra effort usually pays off because the method gets you an answer with the accuracy you require with very little waste. In the end the program almost always takes less time to run, and usually much less.\n",
    "\n",
    "It is possible for the two estimates $x_1 $ and $x_2 $ to coincidentally agree with one another. If this happens, $h'$ can erroneously become very large, causing the calculation to break down. To prevent this, one commonly places an upper limit on how much the value of $h$ can increase from one step to another. A common rule of thumb is that it should not increase by more than a factor of two on any given pair of steps (pairs of successive steps being the fundamental unit in the method described here).\n",
    "\n",
    "The adaptive step size method can be used to solve simultaneous differential equations: we need to decide how to generalize the formula for the error to the case of more than one dependent variable. The derivation can be duplicated for each variable\n",
    "\n",
    "$$ \\epsilon _x = \\frac{1}{30}(x_1 - x_2) \\qquad \\qquad \\epsilon _y =  \\frac{1}{30}(y_1 - y_2) $$\n",
    "\n",
    "There is more than one way that these separate errors can be combined into a single overall error, depending on the particular needs of the calculation: if we have variables $x$ and $y$ that represent coordinates of a point in a two-dimensional space, we might wish to perform a calculation that ensures that the Euclidean error $\\sqrt{\\epsilon^2_x + \\epsilon^2_y }$ in the position of the point meets a certain target. On the other hand, suppose we are performing a calculation for the nonlinear pendulum, where we are solving a single second-order equation for $\\theta $ introduce an additional variable $w$ to turn the problem into two first-order equations. In that case we don't really care about $ \\theta $ and its accuracy doesn't matter so long as $\\omega $ is calculated accurately.\n",
    "\n",
    "## Local extrapolation\n",
    "\n",
    "We know\n",
    "\n",
    "$$ x(t+2h) = x_1 + 2ch^5 + O(h^6) \\qquad \\text{and} \\qquad ch^5 = \\frac{1}{30}(x_1 - x_2 ) $$\n",
    "\n",
    "then\n",
    "\n",
    "$$ x(t+2h) = x_1 + \\frac{1}{15}(x_1 - x_2 ) + O(h^6 ) $$\n",
    "\n",
    "which is now accurate to order $h^5$ and has a error of order $h^6$, one order better than the standard fourth-order Runge-Kutta method. The former equation involves only quantities we have already computed, so it's essentially no extra work to calculate this more accurate estimate of the solution.\n",
    "\n",
    "- It is possible to use methods similar to this not only to eliminate the leading-order error, but also any number of higher-order terms as well, resulting in impressively accurate solutions to differential equations even when using quite large values of h. The technique for doing this is called _Richardson extrapolation_ and it's the basis of one of the most powerful methods for solving differential equations.\n",
    "- Richardson extrapolation, however, is not usually used with the Runge-Kutta method, but rather with another method, called the _modified midpoint method_."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
